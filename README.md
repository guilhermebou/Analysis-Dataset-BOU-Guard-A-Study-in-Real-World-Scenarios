# Analysis Dataset: BOU-Guard - A Study in Real-World Scenarios

Este reposit√≥rio cont√©m a an√°lise e o estudo do BOU-Guard, uma ferramenta para detectar discursos ofensivos (racismo, homofobia, sexismo) em cen√°rios reais utilizando coment√°rios de redes sociais como Twitter (X) e Reddit.
Apresentado na [UFU-FACOM | XVIII Workshop de Teses e Disserta√ß√µes em Ci√™ncia da Computa√ß√£o](https://techweek.facom.ufu.br/wtdcc-2024).

## üìã Objetivo

Investigar a viabilidade e o comportamento de Modelos de Linguagem de Grande Escala (LLMs) na detec√ß√£o de discursos ofensivos em redes sociais, comparando o desempenho das vers√µes GPT-3.5 e GPT-4.
Este estudo √© para promover a ferramenta  [`BOU-Guard | Extension`](https://github.com/guilhermebou/BOU-Guard-Extension), realizando uma compara√ß√£o de modelos em um estudo de viabilidade.

## üõ† Estrutura do Reposit√≥rio

- `data/`  
  Cont√©m os datasets analisados no estudo.  
- `python/`  
  Cont√©m os scripts de an√°lise, pr√©-processamento de dados e classifica√ß√£o.  
- `results/`  
  Resultados finais organizados em planilhas.  
- `docs/`  
  documenta√ß√£o para fundamenta√ß√£o.

## üöÄ Funcionalidades

- **Pr√©-processamento de Dados**: Filtragem e organiza√ß√£o de grandes volumes de dados de redes sociais.
- **Classifica√ß√£o Automatizada**: Uso de APIs para identificar conte√∫dos ofensivos em tempo real.
- **Visualiza√ß√£o de Dados**: Apresenta√ß√£o dos resultados em relat√≥rios organizados.

## üß™ Metodologia

1. **Coleta de Dados**: Extra√ß√£o de coment√°rios de redes sociais.
2. **An√°lise**: Classifica√ß√£o utilizando LLMs (GPT-3.5 e GPT-4).
3. **Compara√ß√£o de Resultados**: Medi√ß√£o de desempenho, utilizando metricas como Recall, Precision e F1-SCORE.

## üìä Resultados

Os resultados mostraram uma alta taxa de precis√£o do GPT-4 em rela√ß√£o ao GPT-3.5, com melhorias na identifica√ß√£o de nuances lingu√≠sticas em coment√°rios ofensivos.
### Resultados do BOUGuard - Dataset Result GPT-3.5 (Lemmatization)

| Categoria  | Verdadeiro Positivo (VP) | Falso Positivo (FP) | Falso Negativo (FN) | Precision  | Recall  | F1-Score |
|------------|---------------------------|----------------------|----------------------|------------|---------|----------|
| Homofobia  | 503                       | 0                    | 177                  | 100,00%    | 73,97%  | 85,04%   |
| Sexismo    | 208                       | 0                    | 472                  | 100,00%    | 30,59%  | 46,85%   |
| Racismo    | 387                       | 0                    | 293                  | 100,00%    | 56,91%  | 72,54%   |
| Normal     | 609                       | 0                    | 71                   | 100,00%    | 89,56%  | 94,49%   |

### Resultados do BOUGuard - Dataset Result GPT-3.5 (Sem Lematiza√ß√£o)

| Categoria  | Verdadeiro Positivo (VP) | Falso Positivo (FP) | Falso Negativo (FN) | Precision  | Recall  | F1-Score |
|------------|---------------------------|----------------------|----------------------|------------|---------|----------|
| Homofobia  | 497                       | 0                    | 183                  | 100,00%    | 73,09%  | 84,45%   |
| Sexismo    | 273                       | 0                    | 407                  | 100,00%    | 40,15%  | 57,29%   |
| Racismo    | 341                       | 0                    | 339                  | 100,00%    | 50,15%  | 66,80%   |



### Resultados do BOUGuard - Dataset Result GPT-4 (Lemmatization)

| Categoria  | Verdadeiro Positivo (VP) | Falso Positivo (FP) | Falso Negativo (FN) | Precision  | Recall  | F1-Score |
|------------|---------------------------|----------------------|----------------------|------------|---------|----------|
| Homofobia  | 650                       | 0                    | 30                   | 100,00%    | 95,59%  | 97,74%   |
| Sexismo    | 470                       | 0                    | 210                  | 100,00%    | 69,12%  | 81,74%   |
| Racismo    | 390                       | 0                    | 290                  | 100,00%    | 57,35%  | 72,90%   |
| Normal     | 622                       | 0                    | 58                   | 100,00%    | 91,47%  | 95,55%   |




Analisando os resultados mais minuciosamente, foram encontrados alguns ru√≠dos nos datasets de sexismo e racismo. Neles, n√£o estavam presentes 100% dos coment√°rios correspondentes √†s suas respectivas labels. Por isso, foi realizada uma segunda an√°lise manual, apresentada no arquivo[`manual_analysis_comments_racist_sexist.xlsx`](https://github.com/guilhermebou/Analysis-Dataset-BOU-Guard-A-Study-in-Real-World-Scenarios/blob/main/Data/Results/manual_analysis_comments_racist_sexist.xlsx)

### Resultados da An√°lise Manual de Coment√°rios Racismo e Sexismo

| Categoria            | Verdadeiro Positivo (VP)  | Falso Positivo (FP)  | Falso Negativo (FN)  | Acur√°cia | Precis√£o | Recall | F1-Score |
|----------------------|---------------------------|----------------------|-------------------|----------|----------|--------|----------|
| Sexismo (GPT-4.0)    | 456                       | 52                   | 38                 | 91,67%   | 92,31%   | 89,76% | 91,02%   |
| Sexismo (GPT-3.5)    | 184                       | 24                   | 272                | 40,35%   | 62,64%   | 95,00% | 75,50%   |
| Racismo (GPT-4.0)    | 368                       | 22                   | 82                 | 81,78%   | 95,34%   | 84,59% | 89,64%   |
| Racismo (GPT-3.5)    | 313                       | 74                   | 137                | 69,56%   | 85,88%   | 76,66% | 81,01%   |
